---
title: Diel models
author: Emma
header-includes:
- \usepackage{caption} 
output: 
  pdf_document:
    fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE,  tidy.opts=list(width.cutoff=40),tidy=TRUE, cache = TRUE)
```

```{r startup, results='hide', include=FALSE}
## source necessary packages & functions
library("mgcv")
library("itsadug")
library("ggplot2")
library("viridis")
library("extrafont")
library("grid")
library("reshape2")
library("gridExtra")
library("cowplot")
library("knitr")

#source("../functions/geom_rug3.R")

## create ARn term function
myAR <- function(term, lag) {
  lagterm <- vector(length=length(term))
  for(i in 1:length(term)) {
    if(i <= lag) { lagterm[i] <- NA} else {
      lagterm[i] <- term[i-lag]
    }}
  lagterm
}

## set wd
setwd("../scripts/")

## create a theme to save linespace in plots
papertheme <- theme_bw(base_size=14, base_family = 'Arial') +
  theme(legend.position='top')

## read in data
if (!file.exists('../data/private/bpbuoy2014-mod.rds')) {
  source("diel-buffalo.R")} #creates both 2014 and 2015 data
bdat4 <- readRDS('../data/private/bpbuoy2014-mod.rds')
bdat4 <- bdat4[order(bdat4$datetime),]

bdat5 <- readRDS('../data/private/bpbuoy2015-mod.rds')
bdat5 <- bdat5[order(bdat5$datetime),]

if (!file.exists("../data/private/bp-stability2015.rds")) {
  source("./bp-stratification.R")
}
schmidt <- readRDS("../data/private/bp-stability.rds") # note this for 2014
bdat4 <- merge(bdat4, schmidt)

schmidt5 <- readRDS("../data/private/bp-stability2015.rds") # note this for 2014
bdat5 <- merge(bdat5, schmidt5)

## create index of potential convective mixing, based on diff in T btw air and water
bdat4$conv <- bdat4$airtemp - bdat4$temp4 # this is the topmost, 77cm one
bdat5$conv <- bdat5$airtemp - bdat5$temp4 # this is the topmost, 77cm one

## source necessary script
source("bp-gamplots.R")
```

## Nuggets from Gavin on older version
### co2corr models (gam)
"most of the distributions can't be fitted in GLM-like software as they aren't part of the exponential family or aren't very closely related to that family. My advice is always to choose the distribution on the basis of the range of possible values. A concentration can't be negative so you can't use any distribution that allows negative values (Gaussian, t, ...), and it is continuous, so you can't use a discrete distribution like Poisson, Negative binomial etc. The main choices are Gamma (strictly positive, constant coefficient of variation, data), inverse Gaussian (similar to Gamma but with variance increasing at a fast rate as the mean increases), Tweedie (where the Gamma is a special case - it allows for a point mass on 0 so enables data that have support on the range 0 to infinity where as Gamma and inv Gaussian are strictly positive"

"    Emma said:
    may be stupid Q but is inv. gaussian not an option then?

If you have actual 0s then no, as it has support on the positive real values, just like the Gamma. If you don't have 0s, then start with the Gamma - I've rarely seen or needed an inverse Guassian

    Gavin Simpson said:
    I would go back to the first gam() model for mco2te and change the family to tw() and do as I mentioned above and check that you are sufficiently large a basis for the te() by adding suitable k = c(a,b) where a and b are appropriate basis dimensions for the Time and DOY marginals.

or use family = Gamma(link = "log") depending on whether you have 0s or not. The Tweedie can be useful as it has a power parameter that can vary the dispersion and not have it set to a fixed function of the mean^2"

### co2corr models (gamm)
"With the first gamm() models:

    I think you have the coARMA() incorrectly specified. What this corARMA(form = ~ 1) is that the data are correlated in the order they are in the data set. I think we should try to next this structure so that we address short-term AR within a day - the early lag correlations suggest this might be the issue. It will also speed up computation if you try corAR1(form = ~ Time | DOY) (you can do the corARMA() versions later but they aren't very efficient, so see if the corAR1() works first before going to those less efficient versions.
    Having said that, are there missing data?
    you may be under-estimating the smooths; you can specify the basis dimensions for each marginal smooth in the te(); so try te(Time, DOY, bs = c("cc", "tp"), k = c(10, 10)) say, for 100 edfs max minus a couple for identifiability constraints. The default in te() is only to use 5^d edfs where d = 2 in your case for a 2d spline

The bam() models suggest the mean function (the trends over time) haven't been well-estimated. how to set k is demonstrated above for the te() terms in the gamm()."

## Issues with models describing CO2 (or pH) using time variables

I have selected to make models both with pH and CO2. This is because for 2014, we have CO2 data available (which led to the comparison of calculated and measured CO2 for a part of the paper), but for 2015, only pH. 

There are a few overarching questions regarding these models:

1. Since autocorrelation is a problem mostly for predictions, is it absolutely necessary to account for it here since my main aim is to just describe the data? (Time isn't necessarily informative since interannual variation in weather etc is so high... The main point was to display what happens through time, and be able to show that diel fluctuations are smaller than seasonal fluxes, and those in turn are smaller than interannual fluxes)
2. You mentioned a ```gp``` spline before, and a Gamma with log link -- is this something we still should pursue? 
    a. This comes back to what the final model should be: GAMM, BAM or GAM (with ```gp```)
3. How to construct a BAM wisely? e.g. I can choose to almost follow the data completely, which in a way could be what I want?

The stuff I've copy pasted here comes from these model and plotting scripts: diel-buffalo-models.R and bp-gamplots.R.. There's also diel-buffalo-plots.R specifically for the time models, but I thought it best to not go into this until we've decided on how to construct the model(s)?

### Here are the candidate models:

__1. 2014__

Unfortunately I cannot seem to manage a GAMM model with AR(2)....

``` {r timemodels, echo=TRUE}
 bdat <- transform(bdat, co2lag1 = myAR(bdat$co2corr, 1))

## now making all values <5ppm into 5ppm as per discussion on detection limit of probe???
bdat$co2corr[which(bdat$co2corr < 5)] <- 5

## FIXME: in all models that require contiguous time spaces (even if NA in obs) - noticed that bdat has time
##    gaps with diff() (which is a bit strange since all my faulty data changes involved making into NA
##    rather than removing).. so make sure to do this also in original models script in case we do the
##    lags etc.
start = as.POSIXct(" 2014-06-11 19:30:00", tz="Canada/Saskatchewan")
end = as.POSIXct("2014-08-29 23:45:00", tz="Canada/Saskatchewan")
full <- seq(start, end, by=900)

which(!full %in% bdat$datetime)
alltimes <- data.frame(datetime = full)
bdat <- merge(bdat, alltimes, all.x = TRUE)

  ## create models; testing AR inclusion and comparing k with edf to set k (gam.check)
  ## note that "in recent mgcv versions the output in summary() is more reliable than
  ##    the generalised likelihood ratio test we might do to compare a selected model
  ##    with a null one" (GS Oct 16)
  ## FIXME: DOY is eating up as many k's as possible; 80 too many, using most of 70
  ## FIXME: update model by Gav's ryver comments! "Made some progress with time model. 
  ## Change "tp" to "gp" for both DoY terms and remove any k values. Use Gamma and log link. 
  ##    Model will be ok-ish for now. Will look at model with predictors in AM"
  
# interaction term significant -->
  mco2te <- gam(co2corr ~ te(Time, DOY, bs = c("cc","tp"), k=c(10,10)) + s(co2lag1),
                data = bdat, select = TRUE, method = "REML", family = tw,
                na.action = na.exclude)
  ## co2 dependence on previous value dwarfs all other terms... not sure I'm including everything
  ##    correctly? was I meant to do the autoregression separately?
  
  plot(acf(resid(mco2te), na.action = na.exclude)) # autocorrelation after increasing k for te() term 
  #   now down to <0.2

## try gamm approach following fromthebottomoftheheap?
## FIXME: now amended to have a better corARMA definition and also a AR(1) term with Time|DOY
ctrl <- list(niterEM = 0, msVerbose = FALSE, optimMethod="L-BFGS-B") 
testingnull <- gamm(co2corr ~te(Time, DOY, bs = c("cc","tp"), k=c(10,10)), data = bdat, 
                    family=Gamma(link="log"), control = ctrl, verbosePQL = FALSE)
testing1 <- gamm(co2corr ~te(Time, DOY, bs = c("cc","tp"), k=c(10,10)), data = bdat,
                 correlation = corARMA(form = ~ 1, p=1), family=Gamma(link="log"),
                 control = ctrl, verbosePQL = TRUE)
##testing2 <- gamm(co2corr ~te(Time, DOY, bs = c("cc","tp")), data = bdat, 
       ##          correlation = corARMA(form = ~ 1, p=2),
      ##           control = ctrl, verbosePQL = TRUE)
## FIXME: "Error in `coef<-.corARMA`(`*tmp*`, value = value[parMap[, i]]) : 
##    Coefficient matrix not invertible""
testing3 <- gamm(co2corr ~te(Time, DOY, bs = c("cc","tp"), k=c(10,10)), data = bdat,
                 correlation = corAR1(form = ~ Time | DOY), family=Gamma(link="log"),
                 control = ctrl, verbosePQL = TRUE)
```

``` {r gammresids}
res <- resid(testing1$lme, type = "normalized")
acf(res, lag.max = 200, main = "ACF - AR1 errors for gamm (2014)")

```

__2. 2015__ -- note here, much more data available (ca 20000). For ```gamm()```, I got the error ```Error in recalc.corAR1(cSt, list(Xy = as.matrix(val))) : 'Calloc' could not allocate memory (305795169 of 8 bytes) ``` For the ```gamm``` to run, I had to kill firefox, if I could run it at all...  I decided to try ```bam()```

``` {r bammod, echo=TRUE}
## trying bam to see if model fitting improves cause I can perhaps make more complex
## http://www.sfs.uni-tuebingen.de/~jvanrij/Tutorial/GAMM.html#setting-up-a-gamm-model
bamnull <- bam(ph1 ~te(Time, DOY, bs = c("cc","tp")), data = bdat5)

resnull <- resid(bamnull, type = "scaled.pearson")

bamAR1 <- bam(ph1 ~te(Time, DOY, bs = c("cc","tp"), k=25), data = bdat5, rho=0.85, method='REML')
## FIXME: how to choose k intelligently? Can almost just choose to exactly follow the data
## FIXME: could play with setting rho a bit more -- obvs ACF reduces the higher I set it
```

``` {r bamresids}
## NOTE! To get the AR1-accounted residuals here, need to use function 
op <- par(mfrow=c(1,2))
acf(resnull, main = "BAM AR0 residuals (2015)", ylab=NULL)
acf_resid(bamAR1, main = "BAM AR1 residuals (2015)", ylab="avgACF")
par(op)
#https://cran.r-project.org/web/packages/itsadug/vignettes/acf.html

```

### Issues with mechanistic models (CO2 ~ . for 2014, pH ~ . for 2014 and 2015)

These contain the model variables we all selected together in that email chain a good while ago. Here, I was mainly confused by two things

1. All variables were apparently significant, even those with a near-0 "effect". I was confused about whether the ```gam()``` was potentially mistaken....
2. Conductivity shows a very illogical relationship, suggesting it does not have a direct relationship with the ```y``` variable but may be modulated by something else (which in a way makes sense here since it is our proxy for DIC)
3. WHY is 2015 so different from 2014??

__1. CO2 ~ . (2014)__

``` {r co2mechmod, echo=TRUE}
co2mechmod <- gam(co2corr ~ s(chlrfu, by = factor(TimeofDay), k=4) + 
                   s(log(bga1rfu), by = factor(TimeofDay), k=4) + 
                   s(airtemp) + s(log(stability+1), k=3) + s(log(dailyrain+1), k=4) + s(conv) + 
                   s(log(turb), k=4) + s(cdom, k=3) + s(windsp) + s(cond1, k=4),
                 data = bdat4, select = TRUE, method = "REML", family = tw,
                 na.action = na.exclude, control = gam.control(nthreads = 3, trace = FALSE))
```

``` {r co2mechmodplots}
op <- par(mfrow = c(2,2))
gam.check(co2mechmod)
par(op)

summary(co2mechmod)

plot_grid(plotlist = plotlist, ncol=2, nrow=4)
```

__2. pH ~ . (2014, 2015)__

Model exactly the same for both years:

```{r phmechmod, echo=TRUE}
phmechmod4 <- gam(ph1 ~ s(log(chlrfu), by = factor(TimeofDay), k=4) + s(log(bga1rfu), by = factor(TimeofDay), k=4) + 
               s(airtemp) + s(log(stability +1), k=3) + s(log(dailyrain+1), k=4) + s(conv) + 
               s(log(turb), k=4) + s(cdom, k=3) + s(windsp) + s(cond1, k=4),
             data = bdat, select = TRUE, method = "REML", family = gaussian(),
             na.action = na.exclude, control = gam.control(nthreads = 3, trace = FALSE))
# had to put k for some vars to reduce overfitting

phmechmod5 <- gam(ph1 ~ s(log(chlrfu), by = factor(TimeofDay), k=4) + s(log(bga1rfu), by = factor(TimeofDay), k=4) + 
               s(airtemp) + s(log(stability +1), k=3) + s(log(dailyrain+1), k=4) + s(conv) + 
               s(log(turb), k=4) + s(cdom, k=3) + s(windsp) + s(cond1, k=4),
             data = bdat5, select = TRUE, method = "REML", family = gaussian(),
             na.action = na.exclude, control = gam.control(nthreads = 3, trace = FALSE))
```

In 2014, 91% is explained; in 2015, 70%. Some bizarre things are occurring anyway which I'm checking with Helen, like non-overlapping conductivity between 2014 and 2015. cdom looks like in different units, and so does dailyrain. Checking against our long-term data set, conductivity registered by Helen's sonde was higher in 2015 than any historically recorded conductivity by undergrads...

Here's the plots for the two years (2014, then 2015).. Note - convection seems to be happily pulling pH below recorded pH even for recorded values of convection?

``` {r phplots, plot-ref, fig.height=13, fig.width=9, fig.cap="2014 pH model"}
plot_grid(plotlist = plotlist2014, ncol=2, nrow=4)
```



```{r phplots2015, plot-ref, fig.height=13, fig.width=9, fig.cap="2015 pH model"}
plot_grid(plotlist = plotlist2015, ncol=2, nrow=4)
```

## Bonus issues

### Modeling CO2 based on pH and O2 (to demonstrate how closely they interact, to justify dropping them out of mechanistic model, perhaps as appendix material)

1. If a GAM encounters co-varying variables, does it 'select' the more influential variable for the main effect (strong effect spline), and the less influential variable as the rubbish variable (strange/dampened effect spline)
2. Why, according to my models, is the interaction between pH and O2 significant even if plots do not imply so? The added % explained is from 74.8 to 75.2%

``` {r corrmods, echo=TRUE}
co2phmod <- gam(co2corr ~ s(ph1) + s(ODOrel1), method = "REML", family = tw(),
                na.action = na.exclude, data=bdat4, select=TRUE,
                control = gam.control(nthreads = 3, newton = list(maxHalf = 60), trace = FALSE))
co2inter<- gam(co2corr ~ ti(ph1) + ti(ODOrel1) + ti(ph1, ODOrel1), method = "REML", family = tw(),
               na.action = na.exclude, data=bdat4,
               control = gam.control(nthreads = 3, newton = list(maxHalf = 60), trace = FALSE))
## FIXME -- why is the interaction significant when the relationship really just looks simple?
anova(co2phmod, co2inter, test="LRT")

co2phmodte <- gam(co2corr ~ te(ph1, ODOrel1), method = 'REML', family=tw(), na.action = na.exclude, 
                  data=bdat4, select=TRUE,  control = gam.control(nthreads = 3, newton = list(maxHalf = 60), trace = FALSE))
```

``` {r corrplots,plot-ref, fig.height=5, fig.width=7, fig.cap="2014 pCO2 with te() model" }
plot(co2phmodte, scheme=2)
```